{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CazISR8X_HUG"
   },
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. IMPORTING LIBRARIES \n",
    "- Pandas \n",
    "- Numpy\n",
    "- Matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. IMPORTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_df = pd.read_csv(\"50_Startups.csv\")\n",
    "startup_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Profit (y)\n",
    "y = startup_df.iloc[:,-1].values\n",
    "#By using features (X)\n",
    "X = startup_df.iloc[:,:-1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TAKE CARE OF MISSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "startup_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          49\n",
       "Administration     50\n",
       "Marketing Spend    48\n",
       "State               3\n",
       "Profit             50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ENCODING CATEGORICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "     transformers = [('encoder',OneHotEncoder(),[3])],\n",
    "     remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 1.0 86419.7 153514.11 0.0]\n",
      " [0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 1.0 542.05 51743.15 0.0]\n",
      " [0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "# Avoiding the Dummy Variable Trap \n",
    "## ก่อนที่เราจะ spliting dataset เราจะต้อง eliminate 1 column ที่มาจาก multiple binary columns (ซึ่งเราแปลงมาจาก categorical column) \n",
    "## สาเหตุที่เราต้องลบ 1 columnทิ้ง เป็นเพราะว่า เราต้องการให้มันกลายเป็น default Stage ไป หรือก็คือ ค่าคงที่ b ในสมการ multilinear regression -> y = m0x0 + m1X1 + m2x2 + ... +b \n",
    "# เราจะต้องลบ 1 คอลัมน์ทิ้งไป ถ้ามี 5 feature columns ให้ ลดเหลือ 4 เสมอ \n",
    "\n",
    "X = X[:, 1:]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Spliting the dataset into Training set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Training the Multiple Linear Regression Model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression_ml = LinearRegression()\n",
    "regression_ml.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Predict y_predict from X_test using regression_ml we have built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114664.42 105008.31]\n",
      " [ 90593.16  96479.51]\n",
      " [ 75692.84  78239.91]\n",
      " [ 70221.89  81229.06]\n",
      " [179790.26 191050.39]\n",
      " [171576.92 182901.99]\n",
      " [ 49753.59  35673.41]\n",
      " [102276.66 101004.64]\n",
      " [ 58649.38  49490.75]\n",
      " [ 98272.03  97483.56]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regression_ml.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Building the optimal model using Backward Elimination\n",
    "\n",
    "เป็นวิธีการคัดเลือกตัวแปรอิสระ (Independent Variables or Predictors) ออกทีละตัว โดยตัวแปรอิสระที่มีความสัมพันธ์กับตัวแปรตามน้อยที่สุดจะถูกคัดออก ตัวแปรอิสระตัวแรกที่ถูกพิจารณาคัดออกจะมีความสำคัญต่อการทำนายค่าของ Y น้อยที่สุด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1 : Select a significance level to stay in the model (e.g. SL = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 : Fit the full model with all possible predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use for compute the P-Value and evaluate the statistical significance of our independent variables\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# (2.1) Prepare Matrix X to work well with statsmodels.formula.api\n",
    "    #เนื่องจากเราต้องการทำ Backward Elimination เราจึงเอา statmodels libraries มาหาค่า P-Value, SL \n",
    "    #ทำให้เราต้องแปลง y = b0 + b1x1 + b2x2 + bnxn เป็น y = b0x0 + b1x1 + b2x2 + bnxn (โดยที่ x0 มีค่า = 1) เพื่อที่จะให้สามารถใช้งานกับ Statsmodels ได้\n",
    "\n",
    "    # เราเลยจะ Append Column ที่มีค่า 1 เข้าไปใน X ที่เป็น array \n",
    "    # ใช้ np.append(อาเรย์ที่ต้องการทำ, values ที่ต้องการ append เข้่าไป, แกนที่ต้องการ append เข้าไป)\n",
    "    # np.ones(shape,dtype=None,order='C')\n",
    "    # X = np.append(arr=X\n",
    "    #              ,values= np.ones((50,1)).astype(int)\n",
    "    #              ,axis=1\n",
    "    #              )\n",
    "    # However, ถ้าทำแบบด้านบน column ใหม่ที่ append มันจะไปอยู่ด้านหลังสุด ซึ่งเราต้องการให้มันอยู่ด้านหน้าสุด \n",
    "    # So do this instead,\n",
    "\n",
    "X = np.append(arr= np.ones((50,1)).astype(int)\n",
    "             ,values= X \n",
    "             ,axis=1\n",
    "             )\n",
    "#(2.2) before fitting in OLS method in Statsmodels เราต้องสร้าง Optimal Matrix X ขึ้นมา (X_opt)\n",
    "# โดย (X_opt ในตอนแรกจะมี independent variables ครบทุกตัว เนื่องจาก STEP2 เราต้องการ Fit the full model with all possible predictors หรือ independent variables นั่นเอง) \n",
    "    ## X0 = 1\n",
    "    ## X1 = California\n",
    "    ## X2 = Florida\n",
    "    ## X3 = R & D Spend\n",
    "    ## x4 = Administration Cost\n",
    "    ## x5 = Marketing Cost\n",
    "\n",
    "    ## Note : I remove one selecte Dummy Variable Trap (New york -> Default State)  \n",
    "\n",
    "X_opt = X[:,[0,1,2,3,4,5]] \n",
    "# (2.3) fit X_opt to OLS (Ordinary Least Square) to get coefficients of this multilinear regression model\n",
    "X_opt = X_opt.astype(np.float64) \n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 3 : Consider the predictor with the highest P-Value. if P>SL, go to STEP 4, otherwise go to FIN\n",
    "_______________________\n",
    "\n",
    "Question\n",
    "- As we know that we will remove predictors which have the P>SL  so I this that in the first place when we assume hypothesis \n",
    "    - H0 is X1 is not impact to Y\n",
    "    - H1 is X1 is impact to Y\n",
    "\n",
    "so when the result come in like x1 have P<SL we will reject H0 and Accept H1 instead \n",
    "so H0 is X1 is not impact to Y in the first place right ?\n",
    "\n",
    "Answer \n",
    "\n",
    "- Yes, you're correct. In hypothesis testing within the context of regression analysis, we typically start with the assumption that the null hypothesis (\\( H_0 \\)) is true,   which often implies that the predictor variable (\\( X_1 \\)) has no impact on the outcome variable (\\( Y \\)). \n",
    "\n",
    "    So, for example:\n",
    "\n",
    "    - \\( H_0 \\): \\( X_1 \\) has no effect on \\( Y \\) (i.e., \\( \\beta_1 = 0 \\))\n",
    "    - \\( H_1 \\): \\( X_1 \\) has an effect on \\( Y \\) (i.e., \\( \\beta_1 <> 0 \\))\n",
    "\n",
    "    Then, we conduct hypothesis tests, typically using the t-test or F-test, to determine whether there is sufficient evidence to reject the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "    If the p-value associated with the test statistic is less than the significance level (\\( P < SL \\)), we reject the null hypothesis (\\( H_0 \\)) and conclude that there is evidence to suggest that the predictor variable (\\( X_1 \\)) has a statistically significant impact on the outcome variable (\\( Y \\)).\n",
    "\n",
    "    Therefore, when \\( P < SL \\), we indeed reject the initial assumption that \\( X_1 \\) has no impact on \\( Y \\) (i.e., \\( H_0 \\)), and we accept the alternative hypothesis (\\( H_1 \\)) that \\( X_1 \\) does have an impact on \\( Y \\). This supports the inclusion of \\( X_1 \\) in the model.\n",
    "\n",
    "- Conversely, if \\( P >= SL \\), we fail to reject the null hypothesis (\\( H_0 \\)), suggesting that there is insufficient evidence to conclude that \\( X_1 \\) has a significant impact on \\( Y \\). In this case, we may consider removing \\( X_1 \\) from the model to improve simplicity and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "Hi Thanabodee,\n",
    "I'd be glad to help you with the error you're encountering in the context of backward elimination for multiple linear regression using the statsmodels.formula.api module in the Udemy course \"Machine Learning A-Z: AI, Python & R + ChatGPT Prize [2024]\".\n",
    "\n",
    "Understanding the Error:\n",
    "\n",
    "The error message TypeError: Model.from_formula() missing 2 required positional arguments: 'formula' and 'data' indicates that the sm.ols function you're using is expecting a formula string and a data frame as input, but you're providing endog (dependent variable) and exog (independent variables) directly.\n",
    "\n",
    "Correcting the Code:\n",
    "\n",
    "Here's the corrected code snippet that addresses this issue:\n",
    "\n",
    "Python\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    " \n",
    "- Assuming y is your dependent variable and X_opt is your DataFrame with independent variables\n",
    "-    formula = \"y ~ \" + \" + \".join(X_opt.columns)  # Create formula string with all columns from X_opt\n",
    "-   regressor_OLS = smf.ols(formula, data=X_opt).fit()\n",
    "-       regressor_OLS.summary()\n",
    "Explanation:\n",
    "\n",
    "Import statsmodels.formula.api: This line ensures you're using the correct submodule for formula-based model creation.\n",
    "\n",
    "Create Formula String: The formula variable constructs a string that specifies the regression model with y as the dependent variable and all columns of X_opt as independent variables, separated by plus signs (+).\n",
    "\n",
    "Fit the Model: The smf.ols function now takes the formula string (formula) and the data frame (X_opt) as arguments, correctly fitting the model using formula-based specification.\n",
    "\n",
    "Summary: Finally, you can call regressor_OLS.summary() to display the model summary.\n",
    "\n",
    "Additional Considerations:\n",
    "\n",
    "Make sure X_opt is a pandas DataFrame containing your independent variables.\n",
    "\n",
    "Double-check the column names in X_opt to ensure they match the variable names you intend to use in the formula.\n",
    "\n",
    "By following these steps, you should be able to successfully use the statsmodels.formula.api module for backward elimination in your Python code.\n",
    "\n",
    "If you have further questions or need more specific guidance related to the course material, feel free to ask!\n",
    "\n",
    "Regards,\n",
    "\n",
    "Irum\n",
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ค่า P-value ดังนี้\n",
    "\n",
    "    ## X0 = Constant = 1\n",
    "    ## X1 = California                  - Px1 = 0.953\n",
    "    ## X2 = Florida      (x)            - Px2 = 0.990\n",
    "    ## X3 = R & D Spend                 - Px3 = 0.000\n",
    "    ## x4 = Administration Cost         - Px4 = 0.608\n",
    "    ## x5 = Marketing Cost              - Px5 = 0.123\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 4 : Remove the preditor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากเรา Assume ว่าเราอยู่ใน Universe H0 : independent varaibles ของเราจะไม่มี Impact ต่อ y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยเราจะตัดตัวแปรที่ไม่มีนัยยะสำคัญทางสถิติออกก่อน โดยพิจารณาตัวที่ P-value ที่สูงที่สุดออกก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:05:56</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     217.2   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Apr 2024 & \\textbf{  Prob (F-statistic):} &  8.49e-29   \\\\\n",
       "\\textbf{Time:}             &     19:05:56     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1061.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &     1070.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.011e+04  &     6647.870     &     7.537  &         0.000        &     3.67e+04    &     6.35e+04     \\\\\n",
       "\\textbf{x1}    &     220.1585  &     2900.536     &     0.076  &         0.940        &    -5621.821    &     6062.138     \\\\\n",
       "\\textbf{x2}    &       0.8060  &        0.046     &    17.606  &         0.000        &        0.714    &        0.898     \\\\\n",
       "\\textbf{x3}    &      -0.0270  &        0.052     &    -0.523  &         0.604        &       -0.131    &        0.077     \\\\\n",
       "\\textbf{x4}    &       0.0270  &        0.017     &     1.592  &         0.118        &       -0.007    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.758 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.172  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.53e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.563 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           8.49e-29\n",
       "Time:                        19:05:56   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove X2 : เนื่องจากเรา Accept H0 (X ไม่สัมพันธ์กับ y)\n",
    "\n",
    "    ## X0 = Constant = 1\n",
    "    ## X1 = California\n",
    "    ## X2 = Florida      (x)\n",
    "    ## X3 = R & D Spend\n",
    "    ## x4 = Administration Cost\n",
    "    ## x5 = Marketing Cost\n",
    "\n",
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:11:17</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     296.0   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Apr 2024 & \\textbf{  Prob (F-statistic):} &  4.53e-30   \\\\\n",
       "\\textbf{Time:}             &     19:11:17     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          46      & \\textbf{  BIC:               } &     1066.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.012e+04  &     6572.353     &     7.626  &         0.000        &     3.69e+04    &     6.34e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.045     &    17.846  &         0.000        &        0.715    &        0.897     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.051     &    -0.526  &         0.602        &       -0.130    &        0.076     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.016     &     1.655  &         0.105        &       -0.006    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.838 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.442  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.21e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.586 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           4.53e-30\n",
       "Time:                        19:11:17   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove X1 : เนื่องจากเรา Accept H0 (X ไม่สัมพันธ์กับ y)\n",
    "\n",
    "    ## X0 = Constant = 1\n",
    "    ## X1 = California   (x)\n",
    "    ## X2 = Florida      (x)\n",
    "    ## X3 = R & D Spend\n",
    "    ## x4 = Administration Cost\n",
    "    ## x5 = Marketing Cost\n",
    "\n",
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:05:56</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Apr 2024 & \\textbf{  Prob (F-statistic):} &  2.16e-31   \\\\\n",
       "\\textbf{Time:}             &     19:05:56     & \\textbf{  Log-Likelihood:    } &   -525.54   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1057.   \\\\\n",
       "\\textbf{Df Residuals:}     &          47      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.698e+04  &     2689.933     &    17.464  &         0.000        &     4.16e+04    &     5.24e+04     \\\\\n",
       "\\textbf{x1}    &       0.7966  &        0.041     &    19.266  &         0.000        &        0.713    &        0.880     \\\\\n",
       "\\textbf{x2}    &       0.0299  &        0.016     &     1.927  &         0.060        &       -0.001    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.677 & \\textbf{  Durbin-Watson:     } &    1.257  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.161  \\\\\n",
       "\\textbf{Skew:}          & -0.939 & \\textbf{  Prob(JB):          } & 2.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.575 & \\textbf{  Cond. No.          } & 5.32e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.32e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           2.16e-31\n",
       "Time:                        19:05:56   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove X4 : เนื่องจากเรา Accept H0 (X ไม่สัมพันธ์กับ y) \n",
    "## Even it call x2 but it accuary is x4 because it rearrange new order.\n",
    " \n",
    "    ## X0 = 1\n",
    "    ## X1 = California   (x)\n",
    "    ## X2 = Florida      (x)\n",
    "    ## X3 = R & D Spend\n",
    "    ## x4 = Administration Cost (x)\n",
    "    ## x5 = Marketing Cost\n",
    "\n",
    "X_opt = X[:, [0, 3, 5]]\n",
    "\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:05:56</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.947   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     849.8   \\\\\n",
       "\\textbf{Date:}             & Fri, 12 Apr 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-32   \\\\\n",
       "\\textbf{Time:}             &     19:05:56     & \\textbf{  Log-Likelihood:    } &   -527.44   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.903e+04  &     2537.897     &    19.320  &         0.000        &     4.39e+04    &     5.41e+04     \\\\\n",
       "\\textbf{x1}    &       0.8543  &        0.029     &    29.151  &         0.000        &        0.795    &        0.913     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 13.727 & \\textbf{  Durbin-Watson:     } &    1.116  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   18.536  \\\\\n",
       "\\textbf{Skew:}          & -0.911 & \\textbf{  Prob(JB):          } & 9.44e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.361 & \\textbf{  Cond. No.          } & 1.65e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.65e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Fri, 12 Apr 2024   Prob (F-statistic):           3.50e-32\n",
       "Time:                        19:05:56   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove X5 : เนื่องจากเรา Accept H0 (X ไม่สัมพันธ์กับ y)\n",
    "## Even it call x2 but it accuary is x4 because it rearrange new order.\n",
    "\n",
    "    ## X0 = 1\n",
    "    ## X1 = California   (x)\n",
    "    ## X2 = Florida      (x)\n",
    "    ## X3 = R & D Spend\n",
    "    ## x4 = Administration Cost (x)\n",
    "    ## x5 = Marketing Cost (x)\n",
    "\n",
    "X_opt = X[:, [0, 3]]\n",
    "\n",
    "\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________\n",
    "\n",
    "So we get y = b0x0 + b3x3 + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhYhte6t7H4wEK4xPpDWT7",
   "name": "Multiple Linear Regression",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
